{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import os\n",
    "import glob\n",
    "import datetime\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def download_dataset(filename, url, work_dir):\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"[INFO] Downloading flowers17 dataset....\")\n",
    "        filename, _ = urllib.request.urlretrieve(url + filename, filename)\n",
    "        statinfo = os.stat(filename)\n",
    "        print(\"[INFO] Succesfully downloaded \" + filename + \" \" + str(statinfo.st_size) + \" bytes.\")\n",
    "        untar(filename, work_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg_files(members):\n",
    "    for tarinfo in members:\n",
    "        if os.path.splitext(tarinfo.name)[1] == \".jpg\":\n",
    "            yield tarinfo\n",
    "\n",
    "def untar(fname, path):\n",
    "    tar = tarfile.open(fname)\n",
    "    tar.extractall(path=path, members=jpg_files(tar))\n",
    "    tar.close()\n",
    "    print(\"[INFO] Dataset extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    flowers17_url  = \"http://www.robots.ox.ac.uk/~vgg/data/flowers/17/\"\n",
    "    flowers17_name = \"17flowers.tgz\"\n",
    "    train_dir      = \"dataset\"\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "\n",
    "    download_dataset(flowers17_name, flowers17_url, train_dir)\n",
    "    if os.path.exists(train_dir + \"\\\\jpg\"):\n",
    "        os.rename(train_dir + \"\\\\jpg\", train_dir + \"\\\\train2\")\n",
    "\n",
    "\n",
    "\t# get the class label limit\n",
    "    class_limit = 17\n",
    "\n",
    "    # take all the images from the dataset\n",
    "    image_paths = glob.glob(train_dir + \"\\\\train2\\\\*.jpg\")\n",
    "    print(image_paths)\n",
    "\n",
    "    # variables to keep track\n",
    "    label = 0\n",
    "    i = 0\n",
    "    j = 80\n",
    "\n",
    "    # flower17 class names\n",
    "    class_names = [\"daffodil\", \"snowdrop\", \"lilyvalley\", \"bluebell\", \"crocus\",\n",
    "                   \"iris\", \"tigerlily\", \"tulip\", \"fritillary\", \"sunflower\", \n",
    "                   \"daisy\", \"coltsfoot\", \"dandelion\", \"cowslip\", \"buttercup\",\n",
    "                   \"windflower\", \"pansy\"]\n",
    "\n",
    "\t# loop over the class labels\n",
    "    for x in range(1, class_limit+1):\n",
    "        # create a folder for that class\n",
    "        os.makedirs(train_dir + \"\\\\train2\\\\\" + class_names[label])\n",
    "        \n",
    "        # get the current path\n",
    "        cur_path = train_dir + \"\\\\train2\\\\\" + class_names[label] + \"\\\\\"\n",
    "        \n",
    "\t\t# loop over the images in the dataset\n",
    "        for index, image_path in enumerate(image_paths[i:j], start=1):\n",
    "            original_path   = image_path\n",
    "            image_path      = image_path.split(\"\\\\\")\n",
    "            image_file_name = str(index) + \".jpg\"\n",
    "            os.rename(original_path, cur_path + image_file_name)\n",
    "\t\t\n",
    "        i += 80\n",
    "        j += 80\n",
    "        label += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n"
     ]
    }
   ],
   "source": [
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "#--------------------\n",
    "# tunable-parameters\n",
    "#--------------------\n",
    "images_per_class = 80\n",
    "fixed_size       = tuple((500, 500))\n",
    "train_path       = \"dataset/train2/\"\n",
    "h5_data          = 'output/data.h5'\n",
    "h5_labels        = 'output/labels.h5'\n",
    "bins             = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "#d_hu_moments(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_haralick(image):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    # return the result\n",
    "    return haralick\n",
    "#fd_haralick(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the histogram\n",
    "    return hist.flatten()\n",
    "#fd_histogram(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bluebell',\n",
       " 'buttercup',\n",
       " 'coltsfoot',\n",
       " 'cowslip',\n",
       " 'crocus',\n",
       " 'daffodil',\n",
       " 'daisy',\n",
       " 'dandelion',\n",
       " 'fritillary',\n",
       " 'iris',\n",
       " 'lilyvalley',\n",
       " 'pansy',\n",
       " 'snowdrop',\n",
       " 'sunflower',\n",
       " 'tigerlily',\n",
       " 'tulip',\n",
       " 'windflower']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = os.listdir(train_path)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bluebell', 'buttercup', 'coltsfoot', 'cowslip', 'crocus', 'daffodil', 'daisy', 'dandelion', 'fritillary', 'iris', 'lilyvalley', 'pansy', 'snowdrop', 'sunflower', 'tigerlily', 'tulip', 'windflower']\n"
     ]
    }
   ],
   "source": [
    "train_labels.sort()\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] processed folder: bluebell\n",
      "[STATUS] processed folder: buttercup\n",
      "[STATUS] processed folder: coltsfoot\n",
      "[STATUS] processed folder: cowslip\n",
      "[STATUS] processed folder: crocus\n",
      "[STATUS] processed folder: daffodil\n",
      "[STATUS] processed folder: daisy\n",
      "[STATUS] processed folder: dandelion\n",
      "[STATUS] processed folder: fritillary\n",
      "[STATUS] processed folder: iris\n",
      "[STATUS] processed folder: lilyvalley\n",
      "[STATUS] processed folder: pansy\n",
      "[STATUS] processed folder: snowdrop\n",
      "[STATUS] processed folder: sunflower\n",
      "[STATUS] processed folder: tigerlily\n",
      "[STATUS] processed folder: tulip\n",
      "[STATUS] processed folder: windflower\n",
      "[STATUS] completed Global Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "# empty lists to hold feature vectors and labels\n",
    "global_features = []\n",
    "labels          = []\n",
    "\n",
    "# loop over the training data sub-folders\n",
    "for training_name in train_labels:\n",
    "    # join the training data path and each species training folder\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "\n",
    "    # get the current training label\n",
    "    current_label = training_name\n",
    "\n",
    "    # loop over the images in each sub-folder\n",
    "    for x in range(1,images_per_class+1):\n",
    "        # get the image file name\n",
    "        file = dir + \"/\" + str(x) + \".jpg\"\n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        ####################################\n",
    "        # Global Feature extraction\n",
    "        ####################################\n",
    "        fv_hu_moments = fd_hu_moments(image)\n",
    "        fv_haralick   = fd_haralick(image)\n",
    "        fv_histogram  = fd_histogram(image)\n",
    "\n",
    "        ###################################\n",
    "        # Concatenate global features\n",
    "        ###################################\n",
    "        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "\n",
    "        # update the list of labels and feature vectors\n",
    "        labels.append(current_label)\n",
    "        global_features.append(global_feature)\n",
    "\n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "\n",
    "print(\"[STATUS] completed Global Feature Extraction...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (1360, 532)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training Labels (1360,)\n",
      "[STATUS] training labels encoded...\n",
      "[STATUS] feature vector normalized...\n",
      "[STATUS] target labels: [ 0  0  0 ... 16 16 16]\n",
      "[STATUS] target labels shape: (1360,)\n",
      "[STATUS] end of training..\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))\n",
    "\n",
    "# encode the target labels\n",
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"[STATUS] training labels encoded...\")\n",
    "\n",
    "# scale features in the range (0-1)\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(global_features)\n",
    "print(\"[STATUS] feature vector normalized...\")\n",
    "\n",
    "print(\"[STATUS] target labels: {}\".format(target))\n",
    "print(\"[STATUS] target labels shape: {}\".format(target.shape))\n",
    "\n",
    "# save the feature vector using HDF5\n",
    "h5f_data = h5py.File(h5_data, 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
    "\n",
    "h5f_label = h5py.File(h5_labels, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "print(\"[STATUS] end of training..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import warnings\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable-parameters\n",
    "#--------------------\n",
    "num_trees = 100\n",
    "test_size = 0.10\n",
    "seed      = 9\n",
    "train_path = \"dataset/train2\"\n",
    "test_path  = \"dataset/test\"\n",
    "h5_data    = 'output/data.h5'\n",
    "h5_labels  = 'output/labels.h5'\n",
    "scoring    = \"accuracy\"\n",
    "\n",
    "# get the training labels\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# sort the training labels\n",
    "train_labels.sort()\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    os.makedirs(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(random_state=seed)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] features shape: (1360, 532)\n",
      "[STATUS] labels shape: (1360,)\n",
      "[STATUS] training started...\n"
     ]
    }
   ],
   "source": [
    "# variables to hold the results and names\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "# import the feature vector and trained labels\n",
    "h5f_data  = h5py.File(h5_data, 'r')\n",
    "h5f_label = h5py.File(h5_labels, 'r')\n",
    "\n",
    "global_features_string = h5f_data['dataset_1']\n",
    "global_labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "global_features = np.array(global_features_string)\n",
    "global_labels   = np.array(global_labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# verify the shape of the feature vector and labels\n",
    "print(\"[STATUS] features shape: {}\".format(global_features.shape))\n",
    "print(\"[STATUS] labels shape: {}\".format(global_labels.shape))\n",
    "\n",
    "print(\"[STATUS] training started...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (1224, 532)\n",
      "Test data   : (136, 532)\n",
      "Train labels: (1224,)\n",
      "Test labels : (136,)\n"
     ]
    }
   ],
   "source": [
    "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
    "                                                                                          np.array(global_labels),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.499280 (0.057501)\n",
      "LDA: 0.456764 (0.041680)\n",
      "KNN: 0.352939 (0.031636)\n",
      "CART: 0.468972 (0.019043)\n",
      "RF: 0.642083 (0.034902)\n",
      "NB: 0.372564 (0.037347)\n",
      "SVM: 0.043343 (0.027239)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>sd</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.456764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.352939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.468972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.372564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.043343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algo   sd       acc\n",
       "0    LR  0.1  0.499280\n",
       "1   LDA  0.2  0.456764\n",
       "2   KNN  0.3  0.352939\n",
       "3  CART  0.4  0.468972\n",
       "4    RF  0.5  0.642083\n",
       "5    NB  0.6  0.372564\n",
       "6   SVM  0.7  0.043343"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"algo\":[\"LR\", \"LDA\", \"KNN\", \"CART\", \"RF\", \"NB\", \"SVM\"], \"sd\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7], \"acc\":[0.499280,0.456764,0.352939,0.468972,0.642083,0.372564,0.043343]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.figure()\n",
    "ax = df.plot(kind='bar',x='algo', y='acc',figsize=[10,6])\n",
    "ax.set_xlabel(\"algo\")\n",
    "ax.set_ylabel(\"acc\")\n",
    "pyplot.ylim(ymin=0)\n",
    "ax = plt.tight_layout()\n",
    "ax = plt.show()\n",
    "\n",
    "def autolabel(ax):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for acc in ax:\n",
    "        height = acc.get_height()\n",
    "        ax.text(acc.get_x() + acc.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "#autolabel(ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
